{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2c503bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 已移除 AIMessageChunk 合并猴补丁，避免递归重入问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ebfb0e27-4380-4943-832e-7f306be1753e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7c1db8ca-5203-4bc4-9e78-4bd5e2d1b6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import uuid\n",
    "from typing import Any, Dict, List, Optional, TypedDict\n",
    "\n",
    "import importlib.metadata as meta\n",
    "\n",
    "\n",
    "print(meta.version(\"langchain\"))\n",
    "\n",
    "# 添加 backend 目录到 Python 路径，以便导入 app 模块\n",
    "backend_dir = '/root/consult/backend'\n",
    "if backend_dir not in sys.path:\n",
    "    sys.path.insert(0, backend_dir)\n",
    "    print(f\"✅ 已将 {backend_dir} 添加到 Python 路径\")\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.tools import tool as tool_dec\n",
    "from app.utils.progress_broker import get_progress_broker\n",
    "import time\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce2a8c2-4c7e-49c4-95ce-533a04d253d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "09eeb839-5a75-4ac9-8c50-b71b00b20eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HF_ENDPOINT\"]=\"https://hf-mirror.com\"\n",
    "os.environ[\"HF_HUB_DOWNLOAD_PROGRESS\"] = \"1\"\n",
    "os.environ['HF_HUB_OFFLINE'] = '1'  # 禁用 HuggingFace Hub 连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "afa6f819-0339-49a2-a4a0-77abd0b7971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.services.llamaindex_retriever import LlamaIndexRetriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "669cfa16-dda8-4d42-ae25-a014fca18874",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.utils.import_with_timeout import import_symbol_with_timeout\n",
    "LlamaIndexRetriever = import_symbol_with_timeout(\n",
    "    \"app.services.llamaindex_retriever\", \"LlamaIndexRetriever\", timeout_seconds=5.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4a0ed23d-6280-458e-b898-0d0e42440022",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HF_ENDPOINT\"]=\"https://hf-mirror.com\"\n",
    "os.environ[\"HF_HUB_DOWNLOAD_PROGRESS\"] = \"1\"\n",
    "os.environ['HF_HUB_OFFLINE'] = '1'  # 禁用 HuggingFace Hub 连接\n",
    "os.environ['HF_DATASETS_OFFLINE'] = '1'  # 禁用数据集下载\n",
    "os.environ['TRANSFORMERS_OFFLINE'] = '1'  # 禁用 Transformers 在线功能\n",
    "os.environ['HF_HUB_DISABLE_TELEMETRY'] = '1'  # 禁用遥测（避免联网）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e4c373ae-1163-4e49-a91b-964f613d6cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HF_HUB_DOWNLOAD_TIMEOUT'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3bde8bf6-86ac-4cad-835b-6c7440c648ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['LOCAL_BGE_MODEL_DIR'] = '/root/consult/backend/models/bge-large-zh-v1.5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3533b205-46f1-494e-a3ef-19c105c45f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_global = LlamaIndexRetriever.get_instance(\"global\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "05803b81-378e-4e0f-9b27-a3b3d95ac3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.services.web_search_service import get_web_search_service\n",
    "web_search = get_web_search_service()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "01a4906a-fc5f-46e6-b0aa-40e650a2e114",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_workspace = LlamaIndexRetriever.get_instance(\"global\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e438318a-2003-4c5f-94a5-7fd3612f5f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"/root/consult/backend/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ab55cd82-1e8c-429e-a5a0-2175bd2dd7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv('THIRD_PARTY_API_KEY') \n",
    "api_base = os.getenv('THIRD_PARTY_API_BASE') \n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2, openai_api_key=api_key, openai_api_base=api_base).with_config({\"stream\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6cd674",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.messages import AnyMessage, ToolMessage, HumanMessage, AIMessage, SystemMessage\n",
    "import logging\n",
    "import logging, sys\n",
    "from operator import add\n",
    "from dataclasses import asdict\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    stream=sys.stdout,\n",
    "    format=\"%(levelname)s:%(name)s:%(message)s\",\n",
    "    force=True,  # 关键\n",
    ")\n",
    "\n",
    "class QBState(TypedDict):\n",
    "    request: Dict[str, Any]\n",
    "    workspace_id: str\n",
    "    company_name: Optional[str]\n",
    "    target_projects: List[str]\n",
    "    known_info: Dict[str, Any]\n",
    "    global_db_out: str\n",
    "    messages: Annotated[list[AnyMessage], add]\n",
    "    type: str\n",
    "    retry_count: int\n",
    "    max_retries: int\n",
    "    md: str\n",
    "    analysis: str\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "    \n",
    "class QuestionnaireBuilderWorkflow:\n",
    "    def __init__(self, workspace_retriever, global_retriever, web_search_service, llm=None):\n",
    "        self.workspace_retriever = workspace_retriever\n",
    "        self.global_retriever = global_retriever\n",
    "        self.web_search_service = web_search_service\n",
    "        if llm is None:\n",
    "            api_key = os.getenv('THIRD_PARTY_API_KEY') or os.getenv('OPENAI_API_KEY')\n",
    "            api_base = os.getenv('THIRD_PARTY_API_BASE') or os.getenv('OPENAI_BASE_URL', 'https://api.openai.com/v1')\n",
    "            self.llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2, openai_api_key=api_key, openai_api_base=api_base).with_config({\"stream\": False})\n",
    "        else:\n",
    "            self.llm = llm.with_config({\"stream\": False}) if hasattr(llm, \"with_config\") else llm\n",
    "        self.graph = self._build_graph()\n",
    "        self.checkpointer = MemorySaver()\n",
    "        self.compiled_graph = self.graph.compile(checkpointer=self.checkpointer)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    def _build_graph(self) -> StateGraph:\n",
    "        \n",
    "        @tool\n",
    "        def search_global_db(query: str) -> str:\n",
    "            \"\"\"从全局数据库中检索相关数据，全局数据库包含各类政策信息与过去的申请案例，输入具体检索内容\"\"\"\n",
    "            snippets: List[str] = []\n",
    "            # 全局检索（同步包装）\n",
    "            try:\n",
    "                logging.info(f\"[db_search_tool] 开始全局检索: query={query}\")\n",
    "                g_results = asyncio.run(self.global_retriever.retrieve(query=query, top_k=6, use_hybrid=True, use_compression=True))\n",
    "                logging.info(f\"[db_search_tool] 全局检索返回 {len(g_results)} 条结果\")\n",
    "                for r in g_results:\n",
    "                    title = r.get(\"title\") or r.get(\"name\") or r.get(\"document_id\") or \"片段\"\n",
    "                    text = r.get(\"text\") or r.get(\"content\") or \"\"\n",
    "                    snippets.append(f\"[GLOBAL] {title}: {text[:300]}\")\n",
    "            except Exception as e:\n",
    "                logging.info(f\"[db_search_tool] 全局检索失败: {e}\")\n",
    "            return \"\\n\".join(snippets[:12]) or \"未找到有效片段\"\n",
    "        \n",
    "        @tool\n",
    "        def search_web(query: str) -> str:\n",
    "            \"\"\"从网络中检索相关数据；输入中文查询，返回若干条标题与链接摘要\"\"\"\n",
    "            try:\n",
    "                # 如果服务是异步实现，这里用 asyncio.run 同步封装\n",
    "                results = asyncio.run(self.web_search_service.search_web(query=query, num_results=6))\n",
    "            except Exception as e:\n",
    "                logging.info(f\"[web_search_tool] 网络搜索失败: {e}\")\n",
    "                return \"(网络搜索失败)\"\n",
    "            if not results:\n",
    "                return \"(未找到结果)\"\n",
    "            lines: List[str] = []\n",
    "            for idx, r in enumerate(results[:8], 1):\n",
    "                d = asdict(r)\n",
    "                title = d.get(\"title\") or r.get(\"name\") or r.get(\"snippet_title\") or \"未知标题\"\n",
    "                url = d.get(\"url\") or r.get(\"link\") or r.get(\"source_url\") or \"\"\n",
    "                snippet = d.get(\"snippet\") or r.get(\"content\") or r.get(\"desc\") or \"\"\n",
    "                lines.append(f\"[{idx}] {title}\\n{url}\\n{snippet[:200]}\")\n",
    "            print(\"lines\",\"\\n\\n\".join(lines))\n",
    "            return \"\\n\\n\".join(lines)\n",
    "\n",
    "\n",
    "        def db_search_node(state: QBState) -> QBState:\n",
    "\n",
    "            logging.info(f\"db_search_node\")\n",
    "            tp = \", \".join(state.get(\"target_projects\") or [])\n",
    "            known = state.get(\"known_info\") \n",
    "\n",
    "            react_system_text = (\n",
    "                \"你是中国政策与补贴申报顾问。用户希望申请以下项目：{target_projects}\\n\"\n",
    "                \"已知信息（可能不完整）：\\n{known_info}\\n\\n\"\n",
    "                \"目标：输出面向实操的‘申报条件综述’。\\n\"\n",
    "                \"执行方式（严格遵守）：\\n\"\n",
    "                \"1) 如信息不足，循环调用 search_global_db 检索相关片段并综合要点；\\n\"\n",
    "                \"2) 每轮检索后判断是否仍存在关键空缺（资格/门槛/材料/流程/时间/例外情形）；\\n\"\n",
    "                \"3) 若仍有空缺，则继续调用 search_global_db；若已覆盖充分则停止循环；\\n\"\n",
    "                \"4) 最多调用工具 3 次，达到上限后必须仅输出 OK 并停止；\\n\"\n",
    "                # \"5) 完成后仅输出 OK 作为结束信号（禁止提前总结）。\\n\\n\"\n",
    "                \"注意：优先引用明确口径与阈值，并标注来源类别。\"\n",
    "                \n",
    "            ).format(\n",
    "                target_projects=tp or \"未指定\",\n",
    "                known_info=known or \"无\",\n",
    "            )\n",
    "\n",
    "            agent = create_agent(\n",
    "                    model=self.llm,\n",
    "                    tools=[search_global_db],\n",
    "                    system_prompt=react_system_text,\n",
    "                )\n",
    "            message_content = state.get(\"messages\")\n",
    "\n",
    "            # 安全地提取消息内容\n",
    "            def get_content(msg):\n",
    "                if msg is None:\n",
    "                    return \"\"\n",
    "                if isinstance(msg, dict):\n",
    "                    return msg.get(\"content\", \"\")\n",
    "                if hasattr(msg, \"content\"):\n",
    "                    return getattr(msg, \"content\", \"\")\n",
    "                if isinstance(msg, list) and len(msg) > 0:\n",
    "                    return get_content(msg[0])\n",
    "                return str(msg) if msg else \"\"\n",
    "            logging.info(f\"[db_search_tool] 调用开始检索\")\n",
    "            if message_content is not None and len(message_content) > 1:\n",
    "                res_msg = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"根据这些项目生成条件要求总览,已知总结结果：\" + \\\n",
    "                get_content(message_content[-2]) + \"，判断结果\" + get_content(message_content[-1])}]})\n",
    "            else:\n",
    "                res_msg = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"根据这些项目生成条件要求总览\"}]})\n",
    "            prev_msgs = res_msg.get(\"messages\") or []\n",
    "            logging.info(f\"[db_search_tool] 模型检索完成\")\n",
    "            return {\"messages\": prev_msgs}\n",
    "        \n",
    "        def web_search_node(state: QBState) -> QBState:\n",
    "            \"\"\"\n",
    "            使用网络搜索工具对指定项目进行外部信息检索，返回若干检索要点。\n",
    "            仅返回增量键以满足 LangGraph 的合并规则。\n",
    "            \"\"\"\n",
    "            logging.info(\"[web_search_node] start\")\n",
    "            tp = \", \".join(state.get(\"target_projects\") or [])\n",
    "            known = state.get(\"known_info\") or {}\n",
    "            known_blob = \"\\n\".join([f\"- {k}: {v}\" for k, v in list(known.items())[:12]]) if isinstance(known, dict) else str(known)\n",
    "\n",
    "            system_text = (\n",
    "                \"你是网络检索与情报整合助手。目标：围绕‘{target_projects}’项目，为企业用户提供申报所需要点。\\n\"\n",
    "                \"检索与迭代规则（严格执行）：\\n\"\n",
    "                \"1) 先生成一批高质量中文检索词（3-8条），覆盖：申报条件/资格门槛/材料清单/办理流程/关键时间/例外情形/资金标准。必要时加入单位/地名限定。\\n\"\n",
    "                \"2) 强调优先从政府公开网站（如各级政府官网、部门官网、政务公开专栏、政策公告栏、gov.cn 域名等）进行检索，可以先检索官网公告或政策通知的具体发布位置，再深入细分栏目和部门。每轮按检索词调用 search_web 工具获取结果；优先来源顺序：官网/官媒（gov.cn/部门官网/平台）、政策文件与指南、地方主管部门、企查查/企信宝等工商信息、招股书/年报/公告、主流媒体；尽量附原始链接。\\n\"\n",
    "                \"3) 每轮结束自检信息空缺（上述各类要点是否覆盖、是否有明确阈值/关键口径/例外情形），若仍存在空缺，则生成更精准的新检索词（含实体/年份/地区/文号等），再进行下一轮；最多迭代 8 次。\\n\"\n",
    "                \"4) 达到 3 次上限后，必须仅输出：OK，并停止检索与输出；\\n\"\n",
    "                \"5) 输出时先列出‘检索词与命中概览’（按轮次/关键词列举命中情况与链接），再给出‘要点汇总’（分：资格门槛/材料/流程/时间/例外/资金标准），每点后标注来源编号。若信息已充分，请在最后单独一行仅输出：OK。\\n\"\n",
    "                \"注意：避免泛化与编造，尽量引用来源原文口径；同源重复合并；对工商主体信息可调用与企业相关的公开渠道（如：企查查、企信宝），谨慎标注身份字段。\\n\\n\"\n",
    "                \"已知背景（供参考，可能不完整）：\\n{known_info}\"\n",
    "            ).format(target_projects=tp or \"未指定\", known_info=known_blob or \"无\")\n",
    "\n",
    "            agent = create_agent(\n",
    "                model=self.llm,\n",
    "                tools=[search_web],\n",
    "                system_prompt=system_text,\n",
    "            )\n",
    "\n",
    "            # 生成一次性检索提示（也可根据需要改为多轮）\n",
    "            message_content = state.get(\"messages\")\n",
    "            def get_content(msg):\n",
    "                if msg is None:\n",
    "                    return \"\"\n",
    "                if isinstance(msg, dict):\n",
    "                    return msg.get(\"content\", \"\")\n",
    "                if hasattr(msg, \"content\"):\n",
    "                    return getattr(msg, \"content\", \"\")\n",
    "                if isinstance(msg, list) and len(msg) > 0:\n",
    "                    return get_content(msg[0])\n",
    "                return str(msg) if msg else \"\"\n",
    "            logging.info(f\"[db_search_tool] 调用开始检索\")\n",
    "            if message_content is not None and len(message_content) > 1:\n",
    "                res_msg = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"请检索并汇总要点，给出链接与简要摘录,已知总结结果：\" + \\\n",
    "                get_content(message_content[-2]) + \"，判断结果\" + get_content(message_content[-1])}]})\n",
    "            else:\n",
    "                res_msg = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"请检索并汇总要点，给出链接与简要摘录\"}]})\n",
    "            prev_msgs = res_msg.get(\"messages\") or []\n",
    "\n",
    "            print(prev_msgs)    \n",
    "\n",
    "            return {\"messages\": [prev_msgs]}\n",
    "\n",
    "\n",
    "        def summery_node(state: QBState) -> QBState:\n",
    "\n",
    "            logging.info(f\"[summery_node] 开始总结\")\n",
    "\n",
    "            prompt = (\n",
    "                \"你是政策要求材料总结助手。用户希望申请以下项目：{target_projects}\\n\"\n",
    "                \"已知信息（可能不完整）：\\n{known_info}\\n\\n\"\n",
    "                \"你已经从数据库或网络中检索到了相关信息，请你基于这些信息，系统性、详细地总结申报条件要求和必要材料，涵盖但不限于以下方面：资格要求、申报门槛、必需材料、办理流程、关键时间节点、常见例外等。\\n\"\n",
    "                \"请充分整合所有获取到的政策条款、申报文件、案例等数据，对每项条件尽量详细具体，必要时举例说明，并按类别或逻辑结构清晰归纳，帮助用户快速把握核心要点和潜在难点。\\n\"\n",
    "                \"在总结后，请进一步思考和指出：\\n\"\n",
    "                \"1）根据当前信息，还有哪些可能的申报条件、材料或案例尚未被覆盖，建议检索哪些内容以补全信息？\\n\"\n",
    "                \"2）请列出你的补全建议点和你的分析思路，帮助后续继续完善。\"\n",
    "                \"尽量细化到每个条件的具体内容要求\"\n",
    "            )\n",
    "\n",
    "            # 直接从 QBState 获取 ToolMessage\n",
    "\n",
    "            msgs = state.get(\"messages\") or []\n",
    "            tool_texts = [m.content for m in msgs if isinstance(m, ToolMessage)]\n",
    "            tool_blob = \"\\n\\n\".join(tool_texts) if tool_texts else \"（无工具输出）\"\n",
    "            # print(\"tool_blob\",tool_blob)\n",
    "            prompts = [\n",
    "                SystemMessage(content=prompt),\n",
    "                HumanMessage(content=tool_blob),\n",
    "            ]\n",
    "            res_msg = self.llm.invoke(prompts)\n",
    "            logging.info(f\"[summery_node] 总结完成\")\n",
    "            # print(\"res_msg\",res_msg.content)\n",
    "            print(\"[summery node] out\", res_msg)\n",
    "            return {\"messages\": [res_msg]}\n",
    "        \n",
    "        def Judger_node(state: QBState) -> QBState:\n",
    "            \"\"\"\n",
    "            根据总结信息，判断是否需要进行检索，如果要检索具体哪些方案还要检索；受 max_retries 控制。\n",
    "            \"\"\"\n",
    "            logging.info(f\"[Judger_node] 开始判断\")\n",
    "            # 已达最大次数则直接放弃检索\n",
    "            retry_count = int(state.get(\"retry_count\") or 0)\n",
    "            max_retries = int(state.get(\"max_retries\") or 0)\n",
    "            logging.info(f\"retry_count: {retry_count}, max_retries: {max_retries}\")\n",
    "            if retry_count >= max_retries and max_retries > 0:\n",
    "                logging.info(f\"[Judger_node] 已达最大重检索次数: {retry_count}/{max_retries}\")\n",
    "                return {\"type\": \"放弃检索\"}\n",
    "\n",
    "            prompt = (\n",
    "                \"你是申报条件判定助手。用户希望申请以下项目：{target_projects}\\n\"\n",
    "                \"已知信息（可能不完整）：\\n{known_info}\\n\\n\"\n",
    "                \"你已经获得了对申报条件与材料的总结（见下文），请根据这些内容判断：\\n\"\n",
    "                \"你的回答前四个字必须为“库中检索”或“网络检索”或“放弃检索”，用于直接表示是否还需要进一步检索信息；\\n\"\n",
    "                \"之后再给出具体建议方案和理由，但务必保证前四个字为“库中检索”或“网络检索”或“放弃检索”并直接作答；\\n\"\n",
    "                \"例如：\\n\"\n",
    "                \"库中检索，需要进一步检索学历要求、财务指标明细，因为…\\n\"\n",
    "                \"放弃检索，所有关键信息均已覆盖，无需补充。\\n\"\n",
    "                \"网络检索，需要进一步检索学历要求、财务指标明细，因为…\\n\"\n",
    "                \"请严格遵循：前四个字只能为“库中检索”或“网络检索”或“放弃检索”。\"\n",
    "                \"若需要检索, 请列出需检索的具体方案（如：学历要求、财务指标明细等）及你的判定理由。\\n\"\n",
    "            ).format(\n",
    "                target_projects=state.get(\"target_projects\") or \"未指定\",\n",
    "                known_info=state.get(\"known_info\") or \"无\"\n",
    "            )\n",
    "\n",
    "            logging.info(\"总结结果\" + state.get(\"messages\")[-1].content)\n",
    "            # print(state.get(\"messages\"))\n",
    "\n",
    "            prompts = [\n",
    "                SystemMessage(content=prompt),\n",
    "                HumanMessage(content=state.get(\"messages\")[-1].content),\n",
    "            ]\n",
    "            res_msg = self.llm.invoke(prompts)\n",
    "            logging.info(\"[Judger_node] 模型判断完成\")\n",
    "            # 取前3字作为动作标记\n",
    "            type_now = res_msg.content[0:4]\n",
    "            print(\"type_now\",type_now)\n",
    "            print(\"res_msg\",res_msg.content)\n",
    "            logging.info(f\"[Judger_node] 判断结果 {type_now}\")\n",
    "            # 若需要再次检索，则递增 retry_count\n",
    "            print(\"[Judger node] out\", res_msg)\n",
    "            if type_now in (\"库中检索\", \"网络检索\"):\n",
    "                return {\"messages\": [res_msg], \"type\": type_now, \"retry_count\": retry_count + 1}\n",
    "            else:\n",
    "                return {\"messages\": [res_msg], \"type\": type_now}\n",
    "        \n",
    "        def person_info_web_search_node(state: QBState) -> QBState:\n",
    "            \"\"\"\n",
    "            使用网络搜索工具对指定项目进行外部信息检索，返回若干检索要点。\n",
    "            仅返回增量键以满足 LangGraph 的合并规则。\n",
    "            \"\"\"\n",
    "            logging.info(\"[web_search_node] start\")\n",
    "            company_name = \", \".join(state.get(\"company_name\") or [])\n",
    "            known = state.get(\"known_info\") or {}\n",
    "            known_blob = \"\\n\".join([f\"- {k}: {v}\" for k, v in list(known.items())[:12]]) if isinstance(known, dict) else str(known)\n",
    "\n",
    "            system_text = (\n",
    "                \"你是“主体信息核验”检索助手。任务：围绕以下“公司/个人”实体，检索公开渠道并给出可佐证材料与链接，验证其是否满足相关政策申报所需的主体条件与记录。\\n\"\n",
    "                \"检索与迭代规则（严格执行）：\\n\"\n",
    "                \"1) 先生成一批中文检索词（3-8条），覆盖：企业基础信息（名称/统一社会信用代码/注册地/高管股东）、资格资质/行政许可、行政处罚/信用记录、司法文书/裁判/执行、知识产权、公告/年报/招股书/招投标、主流媒体报道等；必要时加入实体/地区/年份/文号限定。\\n\"\n",
    "                \"2) 每轮按检索词调用 search_web 获取结果；优先来源顺序：政府/主管部门官网与平台（gov.cn、地方政务、信用平台、司法/裁判文书网）> 政策文件/公告/年报/招股书/招投标/公示 > 工商主体公开库（企查查、企信宝等）> 主流媒体/权威行业平台；尽量提供原始链接。\\n\"\n",
    "                \"3) 每轮完成后自检覆盖度：上述要点是否覆盖？是否有明确口径/阈值/例外？若仍有空缺，则生成更精准的新检索词（含实体/地区/年份/文号/关键词）并进行下一轮；最多迭代 8 次。\\n\"\n",
    "                \"4) 达到 8 次上限后，必须仅输出：OK，并停止检索与输出。\\n\"\n",
    "                \"输出格式（严格遵循）：\\n\"\n",
    "                \"- 检索词与命中概览（按轮次/关键词列出命中与链接，1-2 行要点）\\n\"\n",
    "                \"- 证据要点汇总（分项：基础信息、资格/许可、处罚/信用、司法/裁判、知识产权、公告/年报/招股/招投标、媒体报道等），每点后标注来源编号\\n\"\n",
    "                \"- 若信息已充分，请在最后单独一行仅输出：OK\\n\"\n",
    "                \"约束：严禁编造；尽量引用来源原文口径；同源重复合并；对个人敏感信息需最小化披露；如无公开记录，明确说明“未检出”；中文输出。\\n\\n\"\n",
    "                \"已知背景（供参考，可能不完整）：\\n{known_info}\\n\"\n",
    "                \"主体名称：\\n{company_name}（如为公司/个人，请在检索词中加入其名称/别名/代码/地区等）\"\n",
    "            ).format(company_name=company_name or \"未指定\", known_info=known_blob or \"无\")\n",
    "\n",
    "            agent = create_agent(\n",
    "                model=self.llm,\n",
    "                tools=[search_web],\n",
    "                system_prompt=system_text,\n",
    "            )\n",
    "\n",
    "            # 生成一次性检索提示（也可根据需要改为多轮）\n",
    "            message_content = state.get(\"messages\")\n",
    "            def get_content(msg):\n",
    "                if msg is None:\n",
    "                    return \"\"\n",
    "                if isinstance(msg, dict):\n",
    "                    return msg.get(\"content\", \"\")\n",
    "                if hasattr(msg, \"content\"):\n",
    "                    return getattr(msg, \"content\", \"\")\n",
    "                if isinstance(msg, list) and len(msg) > 0:\n",
    "                    return get_content(msg[0])\n",
    "                return str(msg) if msg else \"\"\n",
    "            logging.info(f\"[web_search_tool] 调用开始检索\")\n",
    "\n",
    "            retry_count = int(state.get(\"retry_count\") or 0)\n",
    "            max_retries = int(state.get(\"max_retries\") or 0)\n",
    "            logging.info(f\"retry_count: {retry_count}, max_retries: {max_retries}\")\n",
    "            message_list = []\n",
    "            if retry_count >= max_retries and max_retries > 0:\n",
    "                message_list = [message_content[-1],message_content[-3]]\n",
    "                res_msg = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"请检索并汇总要点，给出链接与简要摘录,已知总结结果：\" + \\\n",
    "                get_content(message_content[-1]) + \"，数据库和网络检索已达最大字数，最后一次检索建议：\" + get_content(message_content[-3])}]})\n",
    "            elif message_content is not None and len(message_content) > 1:\n",
    "                message_list = [message_content[-2],message_content[-1]]\n",
    "                res_msg = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"请检索并汇总要点，给出链接与简要摘录,已知总结结果：\" + \\\n",
    "                get_content(message_content[-2]) + \"，判断结果\" + get_content(message_content[-1])}]})\n",
    "            else:\n",
    "                res_msg = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"请检索并汇总要点，给出链接与简要摘录\"}]})\n",
    "            prev_msgs = res_msg.get(\"messages\") or []\n",
    "\n",
    "            print(\"==============person===============\")\n",
    "            print(\"prev_msgs\",prev_msgs)    \n",
    "            print(\"message_content[-1]\",message_content[-1])\n",
    "            print(\"message_content[-3]\",message_content[-3])\n",
    "            \n",
    "            return {\"messages\": message_list + [prev_msgs]}\n",
    "        \n",
    "        def analysis_node(state: QBState) -> QBState:\n",
    "\n",
    "            logging.info(f\"[analysis_node] 开始分析\")\n",
    "\n",
    "            prompt = (\n",
    "                \"你是“申报可行性评估”专家，面向具体申请人（公司/个人）与目标政策。\\n\"\n",
    "                \"目标：基于已检索/整理的信息，给出申请成功可能性的系统评估与改进建议，并产出一份进一步核实问卷大纲。\\n\\n\"\n",
    "\n",
    "                \"工作流程（严格遵循）：\\n\"\n",
    "                \"1) 要求与材料大纲：\\n\"\n",
    "                \"   - 资格条件（主体/行业/规模/资质/信用/地域/时间窗口）\\n\"\n",
    "                \"   - 硬性门槛（营收/投资/纳税/研发/人员/社保/不良记录等阈值）\\n\"\n",
    "                \"   - 佐证材料（营业执照、财务报表、纳税/社保证明、合同、专利/商标、获奖/荣誉等）\\n\"\n",
    "                \"   - 流程与关键时间点（申报节点、审核、异议、公示、发放）\\n\"\n",
    "                \"   - 例外情形与排除条款\\n\"\n",
    "                \"   为每条在括号中标注来源编号（若有）。\\n\\n\"\n",
    "\n",
    "                \"2) 匹配与证据：将申请人信息与要求逐条比对，分组输出：\\n\"\n",
    "                \"   - 已满足（列证据点与来源编号）\\n\"\n",
    "                \"   - 基本满足但需补充（缺失/证据弱项）\\n\"\n",
    "                \"   - 未满足（关键差距）\\n\"\n",
    "                \"   - 不确定/模糊（待核实）\\n\\n\"\n",
    "\n",
    "                \"3) 评分与结论：\\n\"\n",
    "                \"   - 从适配度(40)、合规与信用(20)、材料完备度(20)、流程与时间把控(10)、风险与不确定性(10) 五维度打分并给总分（0-100）。\\n\"\n",
    "                \"   - 给出一句话结论（可行/存在较大不确定/暂不具备），以及三条内的优先行动建议。\\n\\n\"\n",
    "\n",
    "                \"4) 进一步核实问卷：用于向申请人收集关键信息与材料链接（可复制到表单）。\\n\"\n",
    "                \"   - 每个问题包含：提问、所需证据/证明、说明（为什么需要/判定依据）、期望格式（文件/截图/链接/编号）。\\n\"\n",
    "                \"   - 优先覆盖“不确定/模糊”和“基本满足但需补充”的条目，按优先级排序。\\n\"\n",
    "                \"   - 至少给出 8-15 个大方向问题，并细化条目，尽量结构化。\\n\\n\"\n",
    "\n",
    "                \"输出格式（严格遵循，中文）：\\n\"\n",
    "                \"## 一、要求与材料大纲（附来源编号）\\n\"\n",
    "                \"- ...\\n\\n\"\n",
    "                \"## 二、匹配与证据\\n\"\n",
    "                \"### 2.1 已满足\\n\"\n",
    "                \"- 要求A：证据...（来源#1）\\n\"\n",
    "                \"### 2.2 基本满足但需补充\\n\"\n",
    "                \"- 要求B：缺失...（建议补充...）\\n\"\n",
    "                \"### 2.3 未满足\\n\"\n",
    "                \"- 要求C：差距...\\n\"\n",
    "                \"### 2.4 不确定/模糊\\n\"\n",
    "                \"- 要求D：原因...（需核实...）\\n\\n\"\n",
    "                \"## 三、评分与结论（总分：X/100）\\n\"\n",
    "                \"- 适配度：x/40；合规与信用：x/20；材料完备度：x/20；流程与时间：x/10；风险与不确定性：x/10\\n\"\n",
    "                \"- 结论：...\\n\"\n",
    "                \"- 优先行动建议：1) ... 2) ... 3) ...\\n\\n\"\n",
    "                \"## 四、进一步核实问卷\\n\"\n",
    "                \"1) [高优先级] 近两年纳税证明与社保缴纳清单\\n\"\n",
    "                \"   - 证据：税务/社保官方出具文件或截图\\n\"\n",
    "                \"   - 说明：核验硬性门槛与在地贡献\\n\"\n",
    "                \"   - 格式：PDF/官方链接\\n\"\n",
    "                \"2) ...（按此模板列 8-15 条）\\n\\n\"\n",
    "\n",
    "                \"约束：不得编造；如无来源请标注“无明确来源”；仅提炼必要细节；可引用先前‘检索命中’与‘总结’的来源编号。\"\n",
    "            )\n",
    "\n",
    "            # 直接从 QBState 获取 ToolMessage\n",
    "\n",
    "            msgs = state.get(\"messages\") or []\n",
    "            print(\"msgs[-1]\",msgs[-1])\n",
    "            print(\"msgs[-2]\",msgs[-2])\n",
    "            print(\"msgs[-3]\",msgs[-3])\n",
    "            texts = [msg.content for msg in msgs[-1]]+[msgs[-2].content, msgs[-3].content]\n",
    "            print(\"texts\",len(texts))\n",
    "            blob = \"\\n\\n\".join(texts) if texts else \"（无工具输出）\"\n",
    "            print(\"blob\",blob)\n",
    "\n",
    "\n",
    "            agent = create_agent(\n",
    "                model=self.llm,\n",
    "                tools=[],  # 或不传，视你的封装实现而定\n",
    "                system_prompt=prompt,\n",
    "            )\n",
    "            res_msg = agent.invoke(HumanMessage(content=blob))\n",
    "            logging.info(f\"[analysis_node] 分析完成\")\n",
    "            res_list = res_msg.get(\"messages\")\n",
    "            # for i, msg in enumerate(res_list):\n",
    "            #     print(f\"res_list[{i}]:\", msg)\n",
    "            \n",
    "            return {\"analysis\": res_list[0].content}\n",
    "\n",
    "        def query_node(state: QBState) -> QBState:\n",
    "\n",
    "            logging.info(f\"[query_node] 开始分析\")\n",
    "\n",
    "            prompt = (\n",
    "                \"你是一个专业的问卷设计师，负责将问卷大纲细化为具体问题。请根据以下要求执行任务：\"\n",
    "                \"## 任务要求:\"\n",
    "                \"1. **判断必需性**：请根据已有信息，智能判断用户已知哪些信息，无需重复提问，仅针对未知或不完整的信息设计问题。\"\n",
    "                \"2. **细化程度**：将每个需要询问的大纲条目扩展为3-5个具体问题，确保覆盖所有关键维度。\"\n",
    "                \"3. **问题类型**：包含开放式和封闭式问题。\"\n",
    "                \"4. **覆盖范围**：问题应涵盖（但不限于）：\"\n",
    "                \"- 公司基本信息\"\n",
    "                \"- 业务模式\"\n",
    "                \"- 其它业务相关维度\"\n",
    "                \"5. **问题质量**：\"\n",
    "                \"- 问题应清晰明确，避免歧义\"\n",
    "                \"- 包含必要的背景说明\"\n",
    "                \"- 对专业术语提供简要解释\"\n",
    "                \"6. **格式要求**：使用Markdown列表格式输出。已知信息可用备注形式在对应条目后补充“（已知，无需提问）”。\"\n",
    "                \"## 输出示例\"\n",
    "                \"```markdown\"\n",
    "                \"### 公司基本信息\"\n",
    "                \"1. **公司注册名称**：请提供公司的法定注册名称\"\n",
    "                \"2. **成立时间**：公司成立于哪一年？\"\n",
    "                \"3. **主营业务**：请描述公司的主要业务范围\"\n",
    "                \"- 补充说明：包括核心产品/服务\"\n",
    "                \"4. **组织架构**：公司目前有多少个部门？\"\n",
    "                \"- 选项：A. 1-5个 B. 6-10个 C. 10个以上\"\n",
    "                \"（如已知某项信息，直接标注“（已知，无需提问）”而不出现在问题列表）\"\n",
    "                \"```\"\n",
    "            )\n",
    "\n",
    "            # 直接从 QBState 获取 ToolMessage\n",
    "\n",
    "            source = state.get(\"analysis\")\n",
    "\n",
    "\n",
    "            agent = create_agent(\n",
    "                model=self.llm,\n",
    "                tools=[],  # 或不传，视你的封装实现而定\n",
    "                system_prompt=prompt,\n",
    "            )\n",
    "            res_msg = agent.invoke(HumanMessage(content=source))\n",
    "            logging.info(f\"[analysis_node] 分析完成\")\n",
    "            res_list = res_msg.get(\"messages\")\n",
    "            # for i, msg in enumerate(res_list):\n",
    "            #     print(f\"res_list[{i}]:\", msg)\n",
    "            \n",
    "            return {\"md\": res_list[0].content}\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        def router_func(state: QBState):\n",
    "            if state[\"type\"] == \"库中检索\":\n",
    "                return \"db_search\"\n",
    "            elif state[\"type\"] == \"网络检索\":\n",
    "                return \"web_search\"\n",
    "            else:\n",
    "                return \"person_info_web_search\"\n",
    "            \n",
    "        graph = StateGraph(QBState)      \n",
    "        graph.add_node(\"db_search\", db_search_node)\n",
    "        graph.add_node(\"web_search\", web_search_node)\n",
    "        graph.add_node(\"summery\", summery_node)\n",
    "        graph.add_node(\"judger\", Judger_node)\n",
    "        graph.add_node(\"person_info_web_search\", person_info_web_search_node)\n",
    "        graph.add_node(\"analysis\", analysis_node)\n",
    "        graph.add_node(\"query\", query_node)\n",
    "\n",
    "\n",
    "        graph.add_edge(START, \"db_search\")\n",
    "        graph.add_edge(\"db_search\", \"summery\")\n",
    "        graph.add_edge(\"summery\", \"judger\")\n",
    "        graph.add_edge(\"web_search\", \"summery\")\n",
    "        graph.add_edge(\"summery\", \"judger\")\n",
    "        graph.add_conditional_edges(\"judger\", router_func, [\"db_search\",\"web_search\",\"person_info_web_search\"])\n",
    "        graph.add_edge(\"person_info_web_search\", \"analysis\")\n",
    "        graph.add_edge(\"analysis\", \"query\")\n",
    "        graph.add_edge(\"query\", END)\n",
    "    \n",
    "        return graph\n",
    "\n",
    "    async def run(self, request: Dict[str, Any], phase: Optional[str] = None) -> Dict[str, Any]:\n",
    "        initial: QBState = {\n",
    "            \"request\": request,\n",
    "            \"workspace_id\": (request.get(\"workspace_id\") or \"global\"),\n",
    "            \"company_name\": request.get(\"company_name\"),\n",
    "            \"target_projects\": request.get(\"target_projects\", []),\n",
    "            \"known_info\": request.get(\"known_info\", {}),\n",
    "            \"global_db_out\": \"\",\n",
    "            \"type\": \"\",\n",
    "            \"messages\": [],\n",
    "            \"retry_count\": int(request.get(\"retry_count\", 0)),\n",
    "            \"max_retries\": int(request.get(\"max_retries\", 2)),\n",
    "            \"md\": \"\",\n",
    "            \"analysis\": \"\",\n",
    "        }\n",
    "        \n",
    "        # 使用 ainvoke 异步调用，因为我们使用了异步节点\n",
    "        result: QBState = await self.compiled_graph.ainvoke(\n",
    "            initial,\n",
    "            config={\"configurable\": {\"thread_id\": str(uuid.uuid4())}, \"recursion_limit\": 100}\n",
    "        )\n",
    "\n",
    "        # 相位裁剪已移除，直接返回\n",
    "        print(result.get(\"md\"))\n",
    "        return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "50901afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:db_search_node\n",
      "INFO:root:[db_search_tool] 调用开始检索\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.qingyuntop.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:[db_search_tool] 开始全局检索: query=前海十二条 申报条件\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "697c46ae9da240d583ce4a98146e63aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:[db_search_tool] 全局检索返回 6 条结果\n",
      "INFO:httpx:HTTP Request: POST https://api.qingyuntop.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:[db_search_tool] 开始全局检索: query=前海十二条 申报条件 资格 材料 流程\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14caef4cff204f6bb1c4ef4ba6ced4b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:[db_search_tool] 全局检索返回 6 条结果\n",
      "INFO:httpx:HTTP Request: POST https://api.qingyuntop.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:[db_search_tool] 开始全局检索: query=前海十二条 申报条件 例外情形\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e30f7cd1f524a6e9d528cad746593f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:[db_search_tool] 全局检索返回 6 条结果\n",
      "INFO:httpx:HTTP Request: POST https://api.qingyuntop.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:[db_search_tool] 模型检索完成\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[161], line 13\u001b[0m\n\u001b[1;32m      1\u001b[0m workflow \u001b[38;5;241m=\u001b[39m QuestionnaireBuilderWorkflow(\n\u001b[1;32m      2\u001b[0m                     workspace_retriever\u001b[38;5;241m=\u001b[39mretriever_workspace,\n\u001b[1;32m      3\u001b[0m                     global_retriever\u001b[38;5;241m=\u001b[39mretriever_global,\n\u001b[1;32m      4\u001b[0m                     web_search_service\u001b[38;5;241m=\u001b[39mweb_search,\n\u001b[1;32m      5\u001b[0m                     llm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      6\u001b[0m                 )\n\u001b[1;32m      7\u001b[0m request_context \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      8\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworkspace_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglobal\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompany_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m紫荆思源有限公司\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_projects\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m前海十二条\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     11\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mknown_info\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m     12\u001b[0m                 }\n\u001b[0;32m---> 13\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m workflow\u001b[38;5;241m.\u001b[39mrun(request_context)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "Cell \u001b[0;32mIn[160], line 532\u001b[0m, in \u001b[0;36mQuestionnaireBuilderWorkflow.run\u001b[0;34m(self, request, phase)\u001b[0m\n\u001b[1;32m    516\u001b[0m initial: QBState \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    517\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m: request,\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworkspace_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: (request\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworkspace_id\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglobal\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manalysis\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    529\u001b[0m }\n\u001b[1;32m    531\u001b[0m \u001b[38;5;66;03m# 使用 ainvoke 异步调用，因为我们使用了异步节点\u001b[39;00m\n\u001b[0;32m--> 532\u001b[0m result: QBState \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompiled_graph\u001b[38;5;241m.\u001b[39mainvoke(\n\u001b[1;32m    533\u001b[0m     initial,\n\u001b[1;32m    534\u001b[0m     config\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigurable\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthread_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(uuid\u001b[38;5;241m.\u001b[39muuid4())}, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecursion_limit\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m100\u001b[39m}\n\u001b[1;32m    535\u001b[0m )\n\u001b[1;32m    537\u001b[0m \u001b[38;5;66;03m# 相位裁剪已移除，直接返回\u001b[39;00m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmd\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m~/consult/backend/venv/lib/python3.10/site-packages/langgraph/pregel/main.py:3182\u001b[0m, in \u001b[0;36mPregel.ainvoke\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[0m\n\u001b[1;32m   3179\u001b[0m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m Any] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   3180\u001b[0m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 3182\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mastream(\n\u001b[1;32m   3183\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   3184\u001b[0m     config,\n\u001b[1;32m   3185\u001b[0m     context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[1;32m   3186\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdates\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   3187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3188\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m stream_mode,\n\u001b[1;32m   3189\u001b[0m     print_mode\u001b[38;5;241m=\u001b[39mprint_mode,\n\u001b[1;32m   3190\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m   3191\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[1;32m   3192\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[1;32m   3193\u001b[0m     durability\u001b[38;5;241m=\u001b[39mdurability,\n\u001b[1;32m   3194\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3195\u001b[0m ):\n\u001b[1;32m   3196\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   3197\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/consult/backend/venv/lib/python3.10/site-packages/langgraph/pregel/main.py:3000\u001b[0m, in \u001b[0;36mPregel.astream\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2998\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mamatch_cached_writes():\n\u001b[1;32m   2999\u001b[0m     loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 3000\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39matick(\n\u001b[1;32m   3001\u001b[0m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mwrites],\n\u001b[1;32m   3002\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m   3003\u001b[0m     get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[1;32m   3004\u001b[0m     schedule_task\u001b[38;5;241m=\u001b[39mloop\u001b[38;5;241m.\u001b[39maaccept_push,\n\u001b[1;32m   3005\u001b[0m ):\n\u001b[1;32m   3006\u001b[0m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   3007\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m _output(\n\u001b[1;32m   3008\u001b[0m         stream_mode,\n\u001b[1;32m   3009\u001b[0m         print_mode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3012\u001b[0m         asyncio\u001b[38;5;241m.\u001b[39mQueueEmpty,\n\u001b[1;32m   3013\u001b[0m     ):\n\u001b[1;32m   3014\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m o\n",
      "File \u001b[0;32m~/consult/backend/venv/lib/python3.10/site-packages/langgraph/pregel/_runner.py:304\u001b[0m, in \u001b[0;36mPregelRunner.atick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[1;32m    302\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m arun_with_retry(\n\u001b[1;32m    305\u001b[0m         t,\n\u001b[1;32m    306\u001b[0m         retry_policy,\n\u001b[1;32m    307\u001b[0m         stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_astream,\n\u001b[1;32m    308\u001b[0m         configurable\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    309\u001b[0m             CONFIG_KEY_CALL: partial(\n\u001b[1;32m    310\u001b[0m                 _acall,\n\u001b[1;32m    311\u001b[0m                 weakref\u001b[38;5;241m.\u001b[39mref(t),\n\u001b[1;32m    312\u001b[0m                 stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_astream,\n\u001b[1;32m    313\u001b[0m                 retry_policy\u001b[38;5;241m=\u001b[39mretry_policy,\n\u001b[1;32m    314\u001b[0m                 futures\u001b[38;5;241m=\u001b[39mweakref\u001b[38;5;241m.\u001b[39mref(futures),\n\u001b[1;32m    315\u001b[0m                 schedule_task\u001b[38;5;241m=\u001b[39mschedule_task,\n\u001b[1;32m    316\u001b[0m                 submit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubmit,\n\u001b[1;32m    317\u001b[0m                 loop\u001b[38;5;241m=\u001b[39mloop,\n\u001b[1;32m    318\u001b[0m             ),\n\u001b[1;32m    319\u001b[0m         },\n\u001b[1;32m    320\u001b[0m     )\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/consult/backend/venv/lib/python3.10/site-packages/langgraph/pregel/_retry.py:137\u001b[0m, in \u001b[0;36marun_with_retry\u001b[0;34m(task, retry_policy, stream, match_cached_writes, configurable)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m task\u001b[38;5;241m.\u001b[39mproc\u001b[38;5;241m.\u001b[39mainvoke(task\u001b[38;5;241m.\u001b[39minput, config)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    139\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[0;32m~/consult/backend/venv/lib/python3.10/site-packages/langgraph/_internal/_runnable.py:709\u001b[0m, in \u001b[0;36mRunnableSeq.ainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(\n\u001b[1;32m    706\u001b[0m                 step\u001b[38;5;241m.\u001b[39mainvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), context\u001b[38;5;241m=\u001b[39mcontext\n\u001b[1;32m    707\u001b[0m             )\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 709\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m step\u001b[38;5;241m.\u001b[39mainvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m step\u001b[38;5;241m.\u001b[39mainvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/consult/backend/venv/lib/python3.10/site-packages/langgraph/_internal/_runnable.py:473\u001b[0m, in \u001b[0;36mRunnableCallable.ainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(ret)\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 473\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mainvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/consult/backend/venv/lib/python3.10/site-packages/langchain_core/runnables/config.py:603\u001b[0m, in \u001b[0;36mrun_in_executor\u001b[0;34m(executor_or_config, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m executor_or_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(executor_or_config, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    602\u001b[0m     \u001b[38;5;66;03m# Use default executor with context copied from current context\u001b[39;00m\n\u001b[0;32m--> 603\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mget_running_loop()\u001b[38;5;241m.\u001b[39mrun_in_executor(\n\u001b[1;32m    604\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    605\u001b[0m         cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCallable[..., T]\u001b[39m\u001b[38;5;124m\"\u001b[39m, partial(copy_context()\u001b[38;5;241m.\u001b[39mrun, wrapper)),\n\u001b[1;32m    606\u001b[0m     )\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mget_running_loop()\u001b[38;5;241m.\u001b[39mrun_in_executor(executor_or_config, wrapper)\n",
      "\u001b[0;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "workflow = QuestionnaireBuilderWorkflow(\n",
    "                    workspace_retriever=retriever_workspace,\n",
    "                    global_retriever=retriever_global,\n",
    "                    web_search_service=web_search,\n",
    "                    llm=None\n",
    "                )\n",
    "request_context = {\n",
    "                    \"workspace_id\": \"global\",\n",
    "                    \"company_name\": \"紫荆思源有限公司\",\n",
    "                    \"target_projects\": [\"前海十二条\"],\n",
    "                    \"known_info\": {},\n",
    "                }\n",
    "result = await workflow.run(request_context)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
